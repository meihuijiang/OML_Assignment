# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w9vj4UDgE2gYS8zVTpocR1PGdIBv3rkg
"""

# -*- coding: utf-8 -*-

import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from scipy.sparse import csr_matrix
from joblib import Parallel, delayed, cpu_count
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd
from scipy import optimize

class SC4RUXfit:

    def __init__(self):
        
        self.rules = dict()
        self.initNumOfRules = 0
        self.numOfRules = 0

    def predict(self, xvals):
        
        # Parallel prediction
        p = cpu_count()
        xsets = np.array_split(xvals, p)
        
        chunkPreds = Parallel(n_jobs=p, prefer="threads")(
            delayed(self.chunkPredict)(x0) for x0 in xsets)
        
        predictions = np.empty(shape=(0), dtype=int)
        
        for indx in range(len(chunkPreds)):
            predictions = np.append(predictions, chunkPreds[indx]['predictions'])

        return predictions        

    def chunkPredict(self, xvals):
        print(xvals)
        chunkPreds = dict()
        chunkPreds['predictions'] = np.zeros(len(xvals), dtype=int)
        
        for sindx, x0 in enumerate(xvals):
            totvals = np.zeros(len(self.rules[0][-1]), dtype=float)
            approxvals = np.zeros(len(self.rules[0][-1]), dtype=float)
            totnum, approxnum = 0, 0
            trueratios = np.zeros(len(self.rules))
            for rindx, rule in enumerate(self.rules.values()):
                truecount = 0
                # The last value in the list stands for
                # the numbers in each class
                for clause in rule[:-1]:
                    if (clause[1] == 'l'):
                        if (x0[clause[0]] <= clause[2]):
                            truecount = truecount + 1
                    if (clause[1] == 'r'):
                        if (x0[clause[0]] > clause[2]):
                            truecount = truecount + 1
                # Not the last one (class numbers)
                trueratios[rindx] = truecount/(len(rule)-1)
                if (trueratios[rindx] == 1.0):
                    totvals += rule[-1]
                    totnum += 1
                else:
                    approxvals += trueratios[rindx]*rule[-1]
                    approxnum += 1
                    
            if (sum(totvals) > 0.0):
                chunkPreds['predictions'][sindx] = np.argmax(totvals)
            else:
                chunkPreds['predictions'][sindx] = np.argmax(approxvals)
                  
        return chunkPreds


class SC4RUX:

    def __init__(self, rf):
        
        # rf is a fitted Random Forest!        
        self.rf = rf
        self.estimator = None
        self.featureNames = None

    def getRule(self, fitTree, nodeid):

        left = fitTree.tree_.children_left
        right = fitTree.tree_.children_right
        threshold = fitTree.tree_.threshold
        featurenames = [self.featureNames[i] for i in fitTree.tree_.feature]
    
        def recurse(left, right, child, lineage=None):
            if lineage is None:
                lineage = [child]
            if child in left:
                parent = np.where(left == child)[0].item()
                split = 'l'
            else:
                parent = np.where(right == child)[0].item()
                split = 'r'
    
            # The first in the list shows the feature index
            lineage.append((fitTree.tree_.feature[parent], split,
                            threshold[parent], featurenames[parent]))
    
            if parent == 0:
                lineage.reverse()
                return lineage
            else:
                return recurse(left, right, parent, lineage)
    
        rule = recurse(left, right, nodeid)
        # Weighted values for each class in leaf comes from tree_
        # These are later filled with actual numbers instead of weights
        rule[-1] = fitTree.tree_.value[nodeid][0]
    
        return rule   

    def chvatal(self, c, A):

        # Mathematical model
        # minimize     c'x
        # subject to   Ax >= 1
        #              x in {0,1}
        # c: n x 1
        # A: m x n
        
        # number of rows and number of columns        
        m, n = A.shape
        # set of rows (items)
        M = set(range(m))
        # set of columns (sets)
        N = set(range(n))

        # sum(j in J) (1 + wj) * zj
        # Subject to:
        # For each sample i in I, at least one rule j in J covers it:
        # sum(j in J, i in Ij) zj >= 1
        # where Ij is the set of samples covered by rule j.
        # Binary variables:
        # zj in {0, 1} for all j in J.
        # The objective function minimizes 

        selected_rules = []
        
        b=np.ones(m)
        x=optimize.linprog(c, A_ub=-A, b_ub=-b, bounds=[(0,1)])

        R = M
        S = set()
        
        return S

    def fit(self, X, y):
        
        fittedSC4RUX = SC4RUXfit()
        
        _, nOfFeatures = np.shape(X)
        nOfClasses = int(max(y) + 1) # classes start with 0
        
        self.featureNames = ['x[' + str(indx) + ']'
                     for indx in range(nOfFeatures)]

        criterion = self.rf.criterion
        
        # Total number of rules
        nOfRules = 0
        for fitTree in self.rf.estimators_:
            nOfRules += fitTree.get_n_leaves()
        
        # Initial number of rules is stored
        fittedSC4RUX.initNumOfRules = nOfRules
        
        # Parallel construction of SCP matrices
        p = cpu_count()
        estsets = np.array_split(self.rf.estimators_, p)
        
        retdicts = Parallel(n_jobs=p, prefer="threads")(
            delayed(self.chunkFit)(X, y, est, criterion)
            for chunkNo, est in enumerate(estsets))
        
        c = np.empty(shape=(0), dtype=float)
        rows = np.empty(shape=(0), dtype=np.int32)
        cols = np.empty(shape=(0), dtype=np.int32)
        colTreeNos = np.empty(shape=(0), dtype=np.int32)
        colLeafNos = np.empty(shape=(0), dtype=np.int32)
        colChunkNos = np.empty(shape=(0), dtype=np.int32)
        colno = 0
        for chunkNo in range(len(estsets)):
            ncols = len(retdicts[chunkNo]['c'])
            c = np.hstack((c, retdicts[chunkNo]['c']))
            rows = np.hstack((rows, retdicts[chunkNo]['rows']))
            colTreeNos = np.hstack((colTreeNos, retdicts[chunkNo]['colTreeNos']))
            colLeafNos = np.hstack((colLeafNos, retdicts[chunkNo]['colLeafNos']))
            tempcols = colno + retdicts[chunkNo]['cols']
            cols = np.hstack((cols, tempcols))
            colChunkNos = np.hstack((colChunkNos, np.ones(ncols,
                                                        dtype=np.int8)*chunkNo))
            colno = cols[-1]+1
        

        data = np.ones(len(rows), dtype=np.int8)
        A = csr_matrix((data, (rows, cols)), dtype=np.int8)
                
        S = self.chvatal(c, A)
        
        for indx, col in enumerate(S):
            chunkno = colChunkNos[col]
            treeno = colTreeNos[col]
            fitTree = estsets[chunkno][treeno]
            leafno = colLeafNos[col]
            rule = self.getRule(fitTree, leafno)
            fittedSC4RUX.rules[indx] = rule
            
            # Filling the last element in 'rule'
            # with actual numbers in each class
            # not the weighted numbers - Though,
            # we do not use weights for SC4RUX
            y_rules = fitTree.apply(X)
            covers = np.where(y_rules == leafno)
            leafyvals = y[covers]  # yvals of the samples in the leaf
            unique, counts = np.unique(leafyvals, return_counts=True)
            numsinclasses = np.zeros(nOfClasses)
            for ix, i in enumerate(unique):
                numsinclasses[int(i)] = counts[ix]
            fittedSC4RUX.rules[indx][-1] = numsinclasses
            
        fittedSC4RUX.numOfRules = len(S)
        
        return fittedSC4RUX

    def chunkFit(self, X, y, estimators, criterion):
        
        numRules = 0
        for fitTree in estimators:
            numRules += fitTree.get_n_leaves()
        
        retdict = dict()
        
        retdict['c'] = np.zeros(numRules, dtype=float)
        retdict['rows'] = np.empty(shape=(0), dtype=np.int32)
        retdict['cols'] = np.empty(shape=(0), dtype=np.int32)

        retdict['colLeafNos'] = np.zeros(numRules, dtype=np.int32)
        retdict['colTreeNos'] = np.zeros(numRules, dtype=np.int32)
        
        col = 0
        for treeno, fitTree in enumerate(estimators):
            # Tells us which sample is in which leaf
            y_rules = fitTree.apply(X)
            for leafno in np.unique(y_rules):
                covers = np.where(y_rules == leafno)[0]
                retdict['rows'] = np.hstack((retdict['rows'], covers))
                retdict['cols'] = np.hstack((retdict['cols'], 
                                             np.ones(len(covers), dtype=np.int8)*col))                
                leafyvals = np.array(y[covers]) # y values of the samples in the leaf
                unique, counts = np.unique(leafyvals, return_counts=True)
                probs = counts/np.sum(counts)
                if (criterion == 'gini'):
                    retdict['c'][col] = 1 + (1 - np.sum(probs**2)) # 1 + Gini
                else:
                    retdict['c'][col] = 1 + (-np.dot(probs, np.log2(probs))) # 1 + Entropy
                retdict['colLeafNos'][col] = leafno
                retdict['colTreeNos'][col] = treeno
                col += 1
                
        return retdict

##########
bcdata = make_classification(5000, random_state=29)
X, y = bcdata[0], bcdata[1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)

estDT = DecisionTreeClassifier()
print('Accuracy of DT: ', accuracy_score(estDT.fit(X_train, y_train).predict(X_test), y_test))

estRF = RandomForestClassifier()
print('Accuracy of RF: ', accuracy_score(estRF.fit(X_train, y_train).predict(X_test), y_test))

estSC4RUX = SC4RUX(estRF)
fitted_SC = estSC4RUX.fit(X_train, y_train)
print('Accuracy of SC4RUX: ', accuracy_score(fitted_SC.predict(X_test), y_test))
print(fitted_SC.initNumOfRules)
print(fitted_SC.numOfRules)